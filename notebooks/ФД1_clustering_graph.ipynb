{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering of the graph\n",
        "\n",
        "Before doing optimisation we are splitting the graph into separate subclusters."
      ],
      "metadata": {
        "id": "olg_R3bkEm6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import networkx as nx\n",
        "from ortools.sat.python import cp_model\n",
        "\n",
        "from scripts import graph_osm_loader, utils, clustering, centroids_graph_builder\n",
        "\n",
        "sys.path.append('../')\n",
        "\n",
        "GRAPH_ID = 'R13470549'  # R13470549 R2555133 R3766483\n",
        "# graphs from library of graphs graph_osm_loader.py\n",
        "\n",
        "g = graph_osm_loader.get_graph(GRAPH_ID)\n",
        "print(len(g.nodes), len(g.edges))\n"
      ],
      "metadata": {
        "id": "uYj7KqW4EnS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tQcMUvfsF5U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering algorithm\n",
        "\n",
        "Here we will need to select point as representative of each centroid subcluster.\n",
        "\n",
        "This algorithm is using libraries from https://github.com/sb-ai-lab/Ride/fork\n",
        "\n",
        "\n",
        "## Data loading\n",
        "\n",
        "Here we make the example of loading data from both\n",
        "GRAPH_ID = 'R13470549'  and as well as from the osmnx."
      ],
      "metadata": {
        "id": "nhoTRHjBF6Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "import networkx as nx\n",
        "#from ortools.sat.python import cp_model\n",
        "import community  # Direct import (works if package is installed correctly)\n",
        "# Import custom modules from scripts directory\n",
        "from scripts import graph_osm_loader, utils, clustering, centroids_graph_builder\n",
        "\n",
        "# Add parent directory to Python path for module resolution\n",
        "sys.path.append('../')\n",
        "\n",
        "# Define graph ID and load OpenStreetMap graph\n",
        "GRAPH_ID = 'R13470549'  # Example graph IDs: R13470549 R2555133 R3766483\n",
        "g = graph_osm_loader.get_graph(GRAPH_ID)\n",
        "print(len(g.nodes), len(g.edges))  # Print graph statistics\n",
        "\n",
        "partition = community.best_partition(G)\n",
        "\n",
        "# Initialize community detection resolver using Louvain + KMeans clustering\n",
        "cms_resolver = clustering.LouvainKMeansCommunityResolver(resolution=1)\n",
        "\n",
        "# Build centroid graph with timing information\n",
        "t, cg = centroids_graph_builder.CentroidGraphBuilder().build_with_time(g, cms_resolver)\n",
        "\n",
        "# Generate sample points for selected problem\n",
        "N = 10\n",
        "points = list({p for p, u in utils.read_points(GRAPH_ID, g, num=N)})\n",
        "points\n"
      ],
      "metadata": {
        "id": "6i9hCtw5F703"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Precompute all-pairs shortest paths between sample points\n",
        "dst = {(u, v): nx.dijkstra_path_length(g, u, v, weight='length') for u in points for v in points}\n",
        "\n",
        "def get_model(points, dst_matrix, START=None, cms_order=None, initial_X=None, initial_U=None):\n",
        "    \"\"\"Here it will be related to the Traveling Salesman Problem (TSP) with optional constraints\"\"\"\n",
        "    if START is None:\n",
        "        START = points[0]\n",
        "\n",
        "    # Initialize decision variables\n",
        "    X = {}  # X[u,v] = 1 if arc u->v is selected\n",
        "    U = {}  # U[u] = position in tour (for MTZ constraints)\n",
        "    model = cp_model.CpModel()\n",
        "\n",
        "    # Create boolean variables for each possible arc\n",
        "    for v in points:\n",
        "        for u in points:\n",
        "            X[v, u] = model.new_bool_var(f'r_{v}_{u}')\n",
        "        model.add(X[v, v] == 0)  # No self-loops\n",
        "        U[v] = model.new_int_var(name=f'u_{v}', lb=0, ub=N-1)  # Position variables\n",
        "\n",
        "    # Flow conservation constraints\n",
        "    for u in points:\n",
        "        model.add(sum(X[u, v] for v in points) == sum(X[v, u] for v in points))\n",
        "\n",
        "    # Exactly one incoming edge for each node (except start)\n",
        "    for u in points:\n",
        "        if u == START:\n",
        "            pass\n",
        "        else:\n",
        "            model.add(sum(X[v, u] for v in points) == 1)\n",
        "\n",
        "    # Exactly one outgoing edge from start node\n",
        "    model.add(sum(X[START, v] for v in points if v != START) == 1)\n",
        "    U[START] = 0  # Start node position is 0\n",
        "\n",
        "    # MTZ subtour elimination constraints\n",
        "    for u in points:\n",
        "        for v in points:\n",
        "            if v != START:\n",
        "                model.add(U[u] + 1 <= U[v] + (1 - X[u, v]) * 1000)\n",
        "\n",
        "    # Optional cluster ordering constraints\n",
        "    if cms_order is not None:\n",
        "        vals = list(cms_order.items())\n",
        "        vals.sort(key=lambda x: x[1])\n",
        "        for i in range(len(vals)-2):\n",
        "            (k1, v1) = vals[i]\n",
        "            (k2, v2) = vals[i+2]\n",
        "            if v1 == 0 or v1 == len(vals) - 1:\n",
        "                continue\n",
        "            set1 = set()\n",
        "            set2 = set()\n",
        "            # Create sets of nodes for adjacent clusters\n",
        "            for u in points:\n",
        "                if g.nodes()[u]['cluster'] == k2:\n",
        "                    set2.add(u)\n",
        "                elif g.nodes()[u]['cluster'] == k1:\n",
        "                    set1.add(u)\n",
        "            # Add ordering constraints between clusters\n",
        "            for u in set1:\n",
        "                for v in set2:\n",
        "                    model.add(U[u] <= U[v])\n",
        "\n",
        "    # Add initial solution hints if provided\n",
        "    if initial_X is not None:\n",
        "        for (u,v),val in initial_X.items():\n",
        "            model.add_hint(X[u,v],val)\n",
        "    if initial_U is not None:\n",
        "        for u,val in initial_U.items():\n",
        "            model.add_hint(U[u],val)\n",
        "\n",
        "    # Objective: Minimize total tour distance\n",
        "    obj = sum(X[a, b] * int(dst_matrix[a, b]) for a in points for b in points)\n",
        "    model.minimize(obj)\n",
        "    return model, X, U\n",
        "\n",
        "# Get cluster information for points\n",
        "cms_points = list({g.nodes()[p]['cluster'] for p in points})\n",
        "# Precompute distances between cluster centroids\n",
        "cms_dst = {(u, v): nx.dijkstra_path_length(cg.g, u, v, weight='length') for u in cms_points for v in cms_points}\n"
      ],
      "metadata": {
        "id": "hAEnqbklCbRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LSFxxbCYF8Gt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}